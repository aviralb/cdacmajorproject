During this project at CDAC We got lot of problems,We will not consider them very big problems ,we can say them as a new learning 
we got lot of parquet files in different folders name as 

1st of the there we got parquet file formats which are total
in drive there are 43 ,in trip there are 43,one in vehicle and weather having 200 files

total files are - 200+43+43+1=288

now the major challenge is to load parquet files in HDFS but we are not able to load parquet file in HDFS so we use Python Package name as 
pandas it gave us lot of flexibility ,we convert all 288 files in csv then merge in single csv file in different file as we have already drive,trip 
weather folder.

after that we are using differnet Big Data Technologies to mine the information 

main technology we are going to use are Pig,Hive,Pyspark,Hive and Scala...


1-drive 

2-trip 

3-weather

4-Vehicle

Data Description

1. Drive Data (Connected car data) – Data coming from the car-mounted devices, which provides you with the car statistics every second. 
This information will include – Speed, acceleration, engine temperature and other car statistics.


2. Trip – Parameters associated with location of car such as lattitude, longitude, altitude and other similar parameters

3. Weather – Weather condition at different latitude & longitude during different times each day.

4. Vehicle Specifications – Different vehicle technical specifications which comes from the manufacturer of the car.


Solution file must be a single zip containing the 3 csvs for 3 kinds of features with the file names as given below:
•	Engine Features: engine_features.csv
•	Drive Features: drive_features.csv
•	Weather Features: weather_features.csv



1. Engine Features (file name – engine_features.csv)-
Grain - every vehicle aggregated at week start date(Monday) for the complete week in YYYY-MM-DD format.
Sorted - by Vehicle ID and week_start_Date in ascending manner
 
Hints:
•	Convert timezone to PST before any calculations
•	All vehicles from drive data should be in the final output even if you do not have specifications (Fill with 0 if specs are not given)
o	Active horsepower - Engine load / 255 * Max Torque * RPM / 5252
o	Horsepower utilization – Active horsepower / Max Horsepower
o	Torque Utilization - calculated as Engine load/ 255
o	RPM Utilization – RPM / Maximum horsepower rpm


2. Drive features(file name – drive_features.csv) -
Grain – Every trip’s aggregated features at a trip id level.
Sorted - by trip_id in ascending manner
 
Hints:
•	Acceleration m/s is calculated as a change in velocity over time
•	If a vehicle keeps on accelerating continuously over a period of time, please treat them as a single acceleration or 
deacceleration period.

3. Weather features (file name – weather_features.csv)
Here are the weather conditions for your reference and generating weather feature accordingly


Grain – Every vehicle detail should be aggregated at a week start date.
 
Sorted - by vehicle_id and week_start_date in ascending manner
 
Hint: convert time zone to PST before any calculations
 
Assumptions & Hints–
•	Weather data is already in PST and may not need any timezone conversion. You may consider the weather data to be constant 
for complete hour basis. For example- if the temperature is given to be 284.51 for 2017-02-14 19:00:00, it would be the same for
time 2017-02-14 19:15:45 as well.
•	Haversine formula must be utilized to measure the distance between any 2 consecutive points in between the trips.
•	Matches in between datasets must be on geohash precision point 5.
 
Studies have found that - The haversine formula determines the great-circle distance between two points on a 
sphere given their longitudes and latitudes. Important in navigation, it is a special case of a more general formula in spherical trigonometry, the law of haversines, that relates the sides and angles of spherical triangles.
 
Criteria & Rules-
•	Least deviation from the actual result would decide the accuracy of the output.
•	For engine and drive features, we are going to use the absolute percent deviation in between pre-calculated output versus the output provided by you. For weather features, it is going to be calculated as per mean percentage deviation from the actual output.
•	The final score is calculated using the deviation scores after applying weights as follows
Score = 100[W1(1- engine_deviation) + W2(1- drive_deviation) + W3(1- weather_deviation)]
•	Quality of code would be judged on the following parameters – functionality, reusability, modularity, documentation, testing and validation.
•	Should be scalable to be executed on 5 GB data as well.
•	Please note that scoring is going to be done using an automated script and difference in between the field names or order from the above-defined feature may result in zero scoring/error message due to the failure of the scoring script.
•	Participants may do multiple submissions. They would have to select on the platform which one to be treated as the final submission. If not selected, the submission with the highest score would be considered as final.
•	Final winners would be announced only after the submitted code reviews and the analysis of the rest of the document submissions made by the participants.
•	Only 5 submissions per day are allowed
 
Submission Format
Solution checker has 2 upload links - one for solution file (described above) and 1 for code files. Final submission must be done along with code files, however, other submissions can be just made with the solution file.


